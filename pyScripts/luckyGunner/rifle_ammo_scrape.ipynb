{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import urllib.request\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import html\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def strip_price(price):\n",
    "    rtn = ''\n",
    "    aGroup = '0123456789.'\n",
    "    for i in price:\n",
    "        if i in aGroup:\n",
    "            rtn += i\n",
    "    return rtn\n",
    "\n",
    "def get_image(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 \\\n",
    "        (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "        \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "    img = soup.find_all('div', class_='lSSlideOuter')\n",
    "    for i in img:\n",
    "        return i.find('li', {'data-src': True})['data-src']\n",
    "\n",
    "\n",
    "# returns 2 list of http links separated by availability\n",
    "def luckyGunner_availability(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 \\\n",
    "        (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "        \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "    page_body = soup.body\n",
    "    products = soup.find_all('div', class_='main')\n",
    "\n",
    "    \n",
    "    # list of all handgun ammo seperated by availability\n",
    "    products = soup.find_all('div', class_='block-content block-no-padding')\n",
    "    bulletsList = str(products).split('<div class=\"main-category-cols\">')\n",
    "    inStock = bulletsList[1]\n",
    "    outofStock = bulletsList[2]\n",
    "\n",
    "    inStockScrapedLinks, outofStockScrapedLinks = [], []\n",
    "    \n",
    "    inStock = inStock.split(\"</li>\")\n",
    "    inStockScrapedLinks = [re.findall(\"(?P<url>https?://[^\\s]+)\", str(inStockItems)) for inStockItems in inStock]\n",
    "\n",
    "\n",
    "\n",
    "    outofStock = outofStock.split(\"</li>\")\n",
    "    outofStockScrapedLinks = [re.findall(\"(?P<url>https?://[^\\s]+)\", str(outOfStockItems)) for outOfStockItems in outofStock]\n",
    "\n",
    "    inStockCleanLinks = []\n",
    "    outofStockCleanLinks = []\n",
    "    \n",
    "\n",
    "    for i in inStockScrapedLinks:\n",
    "        cleanLink = \"\"\n",
    "        for j in i:\n",
    "            for k in j:\n",
    "                if k != '\"':\n",
    "                    cleanLink += k\n",
    "                    \n",
    "                else:\n",
    "                    inStockCleanLinks.append(cleanLink)\n",
    "                    break\n",
    "                \n",
    "    for i in outofStockScrapedLinks:\n",
    "        cleanLink = \"\"\n",
    "        for j in i:\n",
    "            for k in j:\n",
    "                if k != '\"':\n",
    "                    cleanLink += k\n",
    "                else:\n",
    "                    outofStockCleanLinks.append(cleanLink)\n",
    "                    break\n",
    "    return inStockCleanLinks, outofStockCleanLinks"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def scrapeRifleAmmo(link):\n",
    "    link+=\"?limit=all\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 \\\n",
    "        (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "        \n",
    "    page = requests.get(link)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "    page_body = soup.body\n",
    "    detailPageLinks = []\n",
    "    links = soup.find_all('h3', class_='product-name')\n",
    "    detailProduct = soup.find_all('div', class_='product-shop')\n",
    "\n",
    "    dictLinks = []\n",
    "    imageURL = []\n",
    "    for i in links:\n",
    "        x = i.find('a')\n",
    "        detailPageLinks = x['href']\n",
    "        dictLinks.append(detailPageLinks)\n",
    "        imageURL.append(get_image(detailPageLinks))\n",
    "    \n",
    "    names = []\n",
    "    prices = []\n",
    "    calibers = []\n",
    "    try:\n",
    "        calibers.append(soup.find('div', class_='category-title').text)\n",
    "    except:\n",
    "        print(link)\n",
    "\n",
    "    linkIndex = 0 \n",
    "    imageIndex = 0\n",
    "    list_of_dicts = []\n",
    "    for product in detailProduct:\n",
    "        aDict = {'name': names, 'prices': prices, 'links': dictLinks, 'caliber': calibers, 'imageUrl': imageURL}\n",
    "\n",
    "        # scrape names\n",
    "        name = product.find('a')\n",
    "        name = name.find('span').text\n",
    "        aDict['name'] = name\n",
    "        aDict['imageUrl'] = imageURL[imageIndex]\n",
    "        \n",
    "\n",
    "        # scrape prices\n",
    "        price = product.find('div', class_='price-box')\n",
    "        if \"Special Price\" in str(price):\n",
    "            price = price.find('span', class_='price')\n",
    "            aDict['prices'] = strip_price(price.text)\n",
    "        else:\n",
    "            if 'As low as' in str(price):\n",
    "                price = (price.find('span', class_='price'))\n",
    "                aDict['prices'] = strip_price(price.text)\n",
    "            else:\n",
    "                try:\n",
    "                    prices.append(price.text)\n",
    "                    aDict['prices'] = strip_price(price.text)\n",
    "                except:\n",
    "                    prices.append(\"NOPE\")\n",
    "                    aDict['prices'] = \"out of stock\"\n",
    "\n",
    "        aDict['links'] = dictLinks[linkIndex]\n",
    "        linkIndex += 1\n",
    "        try:\n",
    "            aDict['caliber'] = calibers[0].replace('\\n', '')\n",
    "        except:\n",
    "            print(link)\n",
    "\n",
    "        list_of_dicts.append(aDict)\n",
    "    return list_of_dicts\n",
    "        \n",
    "    \n",
    "    \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "link = \"https://www.luckygunner.com/rifle\"\n",
    "x = luckyGunner_availability(link)\n",
    "ammo_data = {\"type\":\"rifle\", \"ammo_results\": []}\n",
    "ld = []\n",
    "for i in x[0]:\n",
    "    dicts = scrapeRifleAmmo(i)\n",
    "    for j in dicts:\n",
    "        ld.append(j)\n",
    "for i in ld:\n",
    "    ammo_data['ammo_results'].append(i)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from pathlib import Path\n",
    "import os, shutil, glob\n",
    "rel = \"jsonFiles/luckyGunner/ammo\"\n",
    "cwd = Path.cwd()\n",
    "currentPath = str(Path.cwd())+\"\"\n",
    "aCount = 0\n",
    "savePath = str(cwd).replace(\"pyScripts/luckyGunner\", rel)\n",
    "\n",
    "with open(os.path.join(savePath, f\"LGRifleAmmo.json\"), \"w\") as fp:\n",
    "    json.dump(ammo_data, fp)\n",
    "\n",
    "rel = 'crispy-computing-app/crispy-computing-app/jsonFiles/luckyGunner/ammo'\n",
    "cwd = Path.cwd()\n",
    "currentPath = str(Path.cwd())+''\n",
    "savePath = str(cwd).replace(\"pyScripts/luckyGunner\", rel)\n",
    "index = 0\n",
    "with open(os.path.join(savePath, f\"LGRifleAmmo.json\"), \"w\") as fp:\n",
    "    json.dump(ammo_data, fp)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "1502fc925b10548bc063e9113a8dbe6304a6331e79a89971281b734ac35d544e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}