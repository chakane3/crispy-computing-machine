{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import urllib.request\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import html\n",
    "import pandas as pd\n",
    "# import xmltojson\n",
    "import json\n",
    "import requests\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def range_price(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 \\\n",
    "        (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'\n",
    "    }\n",
    "        \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "    lowend = soup.find_all(\"span\", {\"class\":\"value\", \"itemprop\":\"lowprice\", \"content\": True})\n",
    "    highend = soup.find_all(\"span\", {\"class\":\"value\", \"itemprop\":\"highprice\", \"content\": True})\n",
    "    quantityList = []\n",
    "    rangePrice = \"\"\n",
    "\n",
    "    for i in lowend:\n",
    "        rangePrice+=(i[\"content\"])\n",
    "        rangePrice+=\" - \"\n",
    "        break\n",
    "\n",
    "    for i in highend:\n",
    "        rangePrice+=(i[\"content\"])\n",
    "        break\n",
    "\n",
    "    return rangePrice"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def scrape_handguns_helper(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 \\\n",
    "        (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'\n",
    "    }\n",
    "    url+= \"=undefined&start=0&sz=100\"\n",
    "        \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "    ammo = soup.find_all(\"div\", class_=\"pdp-link\")\n",
    "    ammoPrice = soup.find_all(\"div\",  class_=\"tile-body\")\n",
    "    names = []\n",
    "    prices = []\n",
    "    actual_prices = []\n",
    "    for i in ammo:\n",
    "        names.append(i.find(\"span\").text)\n",
    "\n",
    "    for i in ammoPrice:\n",
    "        # if the product has a range of prices go here\n",
    "        if '<span class=\"range\">' in str(i):\n",
    "            x = i.find(\"a\", {\"class\": \"link\", \"href\":True})\n",
    "            prices.append(x[\"href\"])\n",
    "\n",
    "        # if the product has a slashed price, go here\n",
    "        else:\n",
    "            x = (i.find(\"span\", class_=\"sales\"))\n",
    "            prices.append(x.find(\"span\", {\"class\":\"value\", \"content\": True}))\n",
    "\n",
    "\n",
    "    # add prices in the prices list\n",
    "    for i in prices:\n",
    "        if \"http\" in i:\n",
    "            rp = range_price(i)\n",
    "            actual_prices.append(rp)\n",
    "\n",
    "        else:\n",
    "            htmlPriceTag = str(i)\n",
    "            splitHtmlPriceTag = htmlPriceTag.split(\" \")\n",
    "            p =  splitHtmlPriceTag[2].strip('content=\"')\n",
    "            actual_prices.append(str(p))\n",
    "   \n",
    "    try:\n",
    "        productList = pd.DataFrame(\n",
    "            {\"name\": names, \"price\": actual_prices}\n",
    "        )\n",
    "        return productList\n",
    "\n",
    "    except:\n",
    "        print(\"something went wrong\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "link = \"https://www.cheaperthandirt.com/shop-by?cgid=80&searchBy=Gauge\"\n",
    "\n",
    "def scrape_handguns(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 \\\n",
    "        (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'\n",
    "    }\n",
    "        \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "    sections = soup.find_all(\"div\", class_=\"brand-link-list\")\n",
    "\n",
    "    # get caliber number set\n",
    "    caliberNumbers = []\n",
    "    x = soup.find_all('div', class_=\"refinements\")\n",
    "    for i in x:\n",
    "        cn = i.find_all(\"div\", {\"id\": True})\n",
    "        for j in cn:\n",
    "            caliberNumbers.append((j[\"id\"]))\n",
    "\n",
    "    dirtyLinks = []  \n",
    "    \n",
    "    for i in sections:\n",
    "        dirtyLinks.append(i.find_all(\"a\"))\n",
    "\n",
    "    caliberNumberDF = pd.DataFrame(\n",
    "        {\"number\": caliberNumbers, \"section\": dirtyLinks}\n",
    "    )\n",
    "    \n",
    "    arrayOfDicts = []\n",
    "    index = 0\n",
    "    for i in caliberNumberDF[\"section\"]:\n",
    "        linkToCaliberList = []  # links\n",
    "        productDict = {\"sectionNumber\": [], \"name\": [],'caliber': [], \"price\": [], \"link\": []}\n",
    "        for j in i:\n",
    "            aLink = re.findall(\"(?P<url>https?://[^\\s]+)\", str(j))\n",
    "            linkToCaliberList.append(str(aLink[0]).replace('\">', \"\"))\n",
    "\n",
    "\n",
    "        for k in linkToCaliberList:\n",
    "            productDF = scrape_handguns_helper(k)\n",
    "            aNameList = []\n",
    "            aPriceList = []\n",
    "            \n",
    "            for j in productDF[\"name\"]:\n",
    "                aNameList.append(j)\n",
    "            productDict[\"name\"].append(aNameList)\n",
    "\n",
    "            productDict[\"link\"].append(k)\n",
    "            \n",
    "\n",
    "            for j in productDF[\"price\"]:\n",
    "                aPriceList.append(j)\n",
    "            productDict[\"price\"].append(aPriceList)\n",
    "        \n",
    "            \n",
    "        \n",
    "        productDict[\"sectionNumber\"].append(caliberNumbers[index])\n",
    "        arrayOfDicts.append(productDict)\n",
    "        index += 1\n",
    "    return arrayOfDicts"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "ammoDF = scrape_handguns(link)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from pathlib import Path\n",
    "import os, shutil, glob\n",
    "rel = \"jsonFiles/cheaperThanDirt/ammo/shotgun\"\n",
    "cwd = Path.cwd()\n",
    "currentPath = str(Path.cwd())+\"\"\n",
    "aCount = 0\n",
    "savePath = str(cwd).replace(\"pyScripts/cheaperThanDirt\", rel)\n",
    "index = 0\n",
    "\n",
    "\n",
    "for i in ammoDF:\n",
    "    with open(os.path.join(savePath, f\"CTDShotgunAmmo.json{index}\"), \"w\") as fp:\n",
    "        json.dump(i, fp)\n",
    "        index += 1"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "1502fc925b10548bc063e9113a8dbe6304a6331e79a89971281b734ac35d544e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}