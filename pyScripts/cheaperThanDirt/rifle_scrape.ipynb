{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import urllib.request\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import html\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "\n",
    "\n",
    "def range_price(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 \\\n",
    "        (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'\n",
    "    }\n",
    "        \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "    lowend = soup.find_all(\"span\", {\"class\":\"value\", \"itemprop\":\"lowprice\", \"content\": True})\n",
    "    highend = soup.find_all(\"span\", {\"class\":\"value\", \"itemprop\":\"highprice\", \"content\": True})\n",
    "    quantityList = []\n",
    "    rangePrice = \"\"\n",
    "\n",
    "    for i in lowend:\n",
    "        rangePrice+=(i[\"content\"])\n",
    "        rangePrice+=\" - \"\n",
    "        break\n",
    "\n",
    "    for i in highend:\n",
    "        rangePrice+=(i[\"content\"])\n",
    "        break\n",
    "\n",
    "    return rangePrice\n",
    "\n",
    "\n",
    "def get_image(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 \\\n",
    "        (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'\n",
    "    }\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "    imgSoup = soup.find('div', class_='desktop-zoom') # d-block img-fluid primary-image\n",
    "    img = imgSoup.find('img')\n",
    "    \n",
    "    return img['src']\n",
    "\n",
    "\n",
    "\n",
    "def scrape_rifle_helper(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 \\\n",
    "        (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'\n",
    "    }\n",
    "    url+= \"=undefined&start=0&sz=100\"\n",
    "        \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "    ammo = soup.find_all(\"div\", class_=\"pdp-link\")\n",
    "    ammoPrice = soup.find_all(\"div\",  class_=\"tile-body\")\n",
    "    names = []\n",
    "    prices = []\n",
    "    actual_prices = []\n",
    "    img_urls = []\n",
    "    possibleCaliber = soup.find_all(\"li\", class_=\"filter-value\")\n",
    "    caliber = possibleCaliber[0].text\n",
    "    \n",
    "    for i in ammo:\n",
    "        names.append(i.find(\"span\").text)\n",
    "\n",
    "    for i in ammoPrice:\n",
    "        # if the product has a range of prices go here\n",
    "        if '<span class=\"range\">' in str(i):\n",
    "            x = i.find(\"a\", {\"class\": \"link\", \"href\":True})\n",
    "            prices.append(x[\"href\"])\n",
    "\n",
    "        # if the product has a slashed price, go here\n",
    "        else:\n",
    "            x = (i.find(\"span\", class_=\"sales\"))\n",
    "            prices.append(x.find(\"span\", {\"class\":\"value\", \"content\": True}))\n",
    "\n",
    "\n",
    "    # gather product detail links\n",
    "    soup_links = soup.find_all(\"div\", class_=\"pdp-link\")\n",
    "    links = []\n",
    "    for i in soup_links:\n",
    "        aLink = re.findall(\"(?P<url>https?://[^\\s]+)\", str(i))\n",
    "        x = (str(aLink[0]).replace('\">', \"\").replace('\"', \"\"))\n",
    "        links.append(x)\n",
    "        img_urls.append(get_image(x))\n",
    "\n",
    "\n",
    "\n",
    "    # add prices in the prices list\n",
    "    for i in prices:\n",
    "        if \"http\" in i:\n",
    "            rp = range_price(i)\n",
    "            actual_prices.append(rp)\n",
    "\n",
    "        else:\n",
    "            htmlPriceTag = str(i)\n",
    "            splitHtmlPriceTag = htmlPriceTag.split(\" \")\n",
    "            p =  splitHtmlPriceTag[2].strip('content=\"')\n",
    "            actual_prices.append(str(p))\n",
    "   \n",
    "    try:\n",
    "        productList = pd.DataFrame(\n",
    "            {\"name\": names, \"price\": actual_prices, \"link\": links, \"caliber\": caliber.replace(\"\\n\\n\", \"\").replace(\"\\n\\n\\n\", \"\").replace(\"\\n\", \"\"), 'imgUrl': img_urls}\n",
    "        )\n",
    "        return productList\n",
    "\n",
    "    except:\n",
    "        print(\"something went wrong\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "link = \"https://www.cheaperthandirt.com/shop-by?cgid=79&searchBy=Caliber\"\n",
    "\n",
    "def scrape_rifle(url):\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 \\\n",
    "        (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'\n",
    "    }\n",
    "        \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "    sections = soup.find_all(\"div\", class_=\"brand-link-list\")\n",
    "\n",
    "    # get caliber number set\n",
    "    caliberNumbers = []\n",
    "    x = soup.find_all('div', class_=\"refinements\")\n",
    "    for i in x:\n",
    "        cn = i.find_all(\"div\", {\"id\": True})\n",
    "        for j in cn:\n",
    "            caliberNumbers.append((j[\"id\"]))\n",
    "\n",
    "    dirtyLinks = []  \n",
    "    calibers = []\n",
    "    for i in sections:\n",
    "        dirtyLinks.append(i.find_all(\"a\"))\n",
    "        x = (i.find_all(\"a\"))\n",
    "        for j in x:\n",
    "            c = (j.find(\"span\").text)\n",
    "            calibers.append(c)\n",
    "\n",
    "\n",
    "    caliberNumberDF = pd.DataFrame(\n",
    "        {\"number\": caliberNumbers, \"section\": dirtyLinks}\n",
    "    )\n",
    "    \n",
    "    arrayOfLinks = []\n",
    "    index = 0\n",
    "    for i in caliberNumberDF[\"section\"]:\n",
    "        linkToCaliberList = []  # links\n",
    "        for j in i:\n",
    "            aLink = re.findall(\"(?P<url>https?://[^\\s]+)\", str(j))\n",
    "            arrayOfLinks.append(str(aLink[0]).replace('\">', \"\"))\n",
    "\n",
    "    arrayOfDicts = []\n",
    "    aNameList = []\n",
    "    aPriceList = []\n",
    "    aLinkList = []\n",
    "    aCaliberList = []\n",
    "    imagesList = []\n",
    "    \n",
    "    for i in arrayOfLinks:\n",
    "        productDict = {\"caliber\": '', \"names\": '', \"price\": '', \"link\": ''}\n",
    "        productDF = scrape_rifle_helper(i)\n",
    "        for name in productDF[\"name\"]:\n",
    "            aNameList.append(name)\n",
    "\n",
    "        for price in productDF[\"price\"]:\n",
    "            aPriceList.append(price)\n",
    "\n",
    "        for link in productDF[\"link\"]:\n",
    "            aLinkList.append(link)\n",
    "    \n",
    "        for caliber in productDF[\"caliber\"]:\n",
    "            aCaliberList.append(caliber)\n",
    "\n",
    "        for imgUrl in productDF['imgUrl']:\n",
    "            imagesList.append(imgUrl)\n",
    "\n",
    "    ammo_data = {\"type\":\"rifle\", \"ammo_results\": []}\n",
    "        \n",
    "\n",
    "    for i in range(0, len(aNameList)):\n",
    "        x = {\"name\": aNameList[i], \"price\": aPriceList[i], \"caliber\": aCaliberList[i], \"link\": aLinkList[i], 'imgUrl': imagesList[i]}\n",
    "        ammo_data[\"ammo_results\"].append(x)\n",
    "\n",
    "        \n",
    "    return ammo_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "ammo = scrape_rifle(link)\n",
    "from pathlib import Path\n",
    "import os, shutil, glob\n",
    "rel = \"jsonFiles/cheaperThanDirt/ammo\"\n",
    "cwd = Path.cwd()\n",
    "currentPath = str(Path.cwd())+\"\"\n",
    "aCount = 0\n",
    "savePath = str(cwd).replace(\"pyScripts/cheaperThanDirt\", rel)\n",
    "\n",
    "\n",
    "swiftTransferDict = {\"results\": []}\n",
    "\n",
    "with open(os.path.join(savePath, f\"CTDRifleAmmo.json\"), \"w\") as fp:\n",
    "    json.dump(ammo, fp)\n",
    "\n",
    "\n",
    "\n",
    "rel = 'crispy-computing-app/crispy-computing-app/jsonFiles/cheaperThenDirt/ammo'\n",
    "cwd = Path.cwd()\n",
    "currentPath = str(Path.cwd())+''\n",
    "savePath = str(cwd).replace(\"pyScripts/cheaperThanDirt\", rel)\n",
    "index = 0\n",
    "with open(os.path.join(savePath, f\"CTDRifleAmmo.json\"), \"w\") as fp:\n",
    "    json.dump(ammo, fp)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "1502fc925b10548bc063e9113a8dbe6304a6331e79a89971281b734ac35d544e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}